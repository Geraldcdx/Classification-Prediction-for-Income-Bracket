{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aeee2f9",
   "metadata": {},
   "source": [
    "Variant 2\n",
    "In this variant, you will compare two existing implementations of classifiers. You can choose any two\n",
    "existing implementations of classification models. Train and test them on the dataset provided in the\n",
    "beginning. Compare the two models using techniques for classification model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea1820",
   "metadata": {},
   "source": [
    "Reporting\n",
    "Your submission for this assignment is a single PDF file with a report on the assignment. Your report\n",
    "should be no longer than two pages. Somewhere at the top of the first page should be: your matric\n",
    "number, full name, and a line “IN6227-2023-Assignment-1.2”. The only requirement for report\n",
    "formatting is that it is readable, otherwise you are free to arrange information in any way you prefer.\n",
    "Make sure to provide full performance comparison for the two models including the time it took to\n",
    "train and apply the model. Explain all decisions you make along the way, e.g., how you fine-tune\n",
    "model hyper-parameters, how you work with missing values, what is the stopping criterion, etc. If\n",
    "you do any data pre-processing, please explain what and why was done.\n",
    "Please upload your source code to GitHub and provide the repository link in the report.\n",
    "Submission\n",
    "Submission should be done in NTULearn. Access the assignment submission page through the left\n",
    "navigation bar by selecting “Assignments”. Submit a single PDF file. Submissions are accepted up to\n",
    "Friday, 3\n",
    "rd March 2023, 23:59:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6365735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#for random forest\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#for MLP\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#Preprocessing libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#https://archive.ics.uci.edu/ml/datasets/Census%2BIncome\n",
    "headers = [\n",
    "    'age','workclass', 'fnlwgt', 'education', 'edu-num', 'martial-status', 'occupation',\n",
    "    'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country' , 'label'     \n",
    "          ]\n",
    "data =  pd.read_csv('adult.data', sep=\",\", names = headers) \n",
    "data.columns\n",
    "\n",
    "#get test data\n",
    "test =  pd.read_csv('adult.test', sep=\",\", names = headers)\n",
    "test = test.iloc[1: , :] #get rid of first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d20c212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.unique() #two kinds of tables only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb554449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data,pca_num): #data is encoded, scaled and conducted PCA\n",
    "    #encode the data\n",
    "    encoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        data[col] = encoder.fit_transform(data[col])\n",
    "    #split data set into features and label\n",
    "    labels = data['label']\n",
    "    features = data.drop(\"label\", axis = 'columns')\n",
    "    features = features\n",
    "    #scale the data\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    #apply PCA\n",
    "    length_of_PCA = pca_num\n",
    "    PCA_columns = []\n",
    "#     for num in range(1, length_of_PCA + 1):\n",
    "#         PCA_columns.append('principal component ' + str(num)) \n",
    "#     pca = PCA(n_components= length_of_PCA)\n",
    "    features = pca.fit_transform(features)\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d77c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision: to use Random Forest and MLP\n",
    "#MLP\n",
    "def preprocessing(data,pca_num): #data is encoded, scaled and conducted PCA\n",
    "    #encode the data\n",
    "    encoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        data[col] = encoder.fit_transform(data[col])\n",
    "    #split data set into features and label\n",
    "    labels = data['label']\n",
    "    features = data.drop(\"label\", axis = 'columns')\n",
    "    features = features\n",
    "    #scale the data\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    #apply PCA\n",
    "#     length_of_PCA = pca_num\n",
    "#     PCA_columns = []\n",
    "#     for num in range(1, length_of_PCA + 1):\n",
    "#         PCA_columns.append('principal component ' + str(num)) \n",
    "#     pca = PCA(n_components= length_of_PCA)\n",
    "#     features = pca.fit_transform(features)\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e9f3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6513/6513 [==============================] - 26s 4ms/step - loss: 0.3403 - accuracy: 0.8409\n",
      "Epoch 2/10\n",
      "6513/6513 [==============================] - 21s 3ms/step - loss: 0.3210 - accuracy: 0.8481\n",
      "Epoch 3/10\n",
      "6513/6513 [==============================] - 21s 3ms/step - loss: 0.3167 - accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "6513/6513 [==============================] - 21s 3ms/step - loss: 0.3142 - accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "6513/6513 [==============================] - 19s 3ms/step - loss: 0.3113 - accuracy: 0.8541\n",
      "Epoch 6/10\n",
      "6513/6513 [==============================] - 14s 2ms/step - loss: 0.3088 - accuracy: 0.8539\n",
      "Epoch 7/10\n",
      "6513/6513 [==============================] - 13s 2ms/step - loss: 0.3073 - accuracy: 0.8553\n",
      "Epoch 8/10\n",
      "6513/6513 [==============================] - 13s 2ms/step - loss: 0.3059 - accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "6513/6513 [==============================] - 13s 2ms/step - loss: 0.3030 - accuracy: 0.8561\n",
      "Epoch 10/10\n",
      "6513/6513 [==============================] - 11s 2ms/step - loss: 0.3018 - accuracy: 0.8580\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3188 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3188125193119049, 0.8500092029571533]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using MLP with some basic tuning\n",
    "component_num = 14\n",
    "features, labels = preprocessing(data,component_num)\n",
    "test_features,test_labels = preprocessing(test,component_num)\n",
    "MLP = Sequential()\n",
    "MLP.add(Dense(units = 50, input_shape=(14,), activation='relu'))\n",
    "MLP.add(Dense(units = 200, activation='relu'))\n",
    "MLP.add(Dense(1, activation='sigmoid'))\n",
    "MLP.compile(optimizer='adam',\n",
    "                loss= 'binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "MLP.fit(features,labels, epochs = 10,batch_size = 5)\n",
    "MLP.evaluate(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e81a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 Complete [00h 00m 29s]\n",
      "val_accuracy: 0.8542914390563965\n",
      "\n",
      "Best val_accuracy So Far: 0.8549055457115173\n",
      "Total elapsed time: 00h 28m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 368, the optimal number of units in the second densely-connected\n",
      "layer is 304, and the optimal learning rate for the optimizer\n",
      "is 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/tutorials/keras/keras_tuner in order to test up some kind of tuning\n",
    "import keras_tuner as kt\n",
    "component_num = 14\n",
    "features, labels = preprocessing(data,component_num)\n",
    "test_features,test_labels = preprocessing(test,component_num)\n",
    "def model_builder(hp):\n",
    "    MLP = Sequential()\n",
    "    hp_first_layer = hp.Int('first_layer', min_value=16, max_value=512, step=32)\n",
    "    MLP.add(Dense(units = hp_first_layer, input_shape=(14,), activation='relu'))\n",
    "    hp_second_layer = hp.Int('second_layer', min_value=16, max_value=512, step=32)\n",
    "    MLP.add(Dense(units = hp_second_layer, activation='relu'))\n",
    "    MLP.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    MLP.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss= 'binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return MLP\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt'\n",
    "                    )\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "#tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "tuner.search(features, labels, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('first_layer')}, the optimal number of units in the second densely-connected\n",
    "layer is {best_hps.get('second_layer')}, and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eeac2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "814/814 [==============================] - 4s 4ms/step - loss: 0.3812 - accuracy: 0.8273 - val_loss: 0.3390 - val_accuracy: 0.8376\n",
      "Epoch 2/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3347 - accuracy: 0.8444 - val_loss: 0.3285 - val_accuracy: 0.8446\n",
      "Epoch 3/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3259 - accuracy: 0.8481 - val_loss: 0.3283 - val_accuracy: 0.8457\n",
      "Epoch 4/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3219 - accuracy: 0.8499 - val_loss: 0.3235 - val_accuracy: 0.8494\n",
      "Epoch 5/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3185 - accuracy: 0.8514 - val_loss: 0.3233 - val_accuracy: 0.8477\n",
      "Epoch 6/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3162 - accuracy: 0.8538 - val_loss: 0.3217 - val_accuracy: 0.8515\n",
      "Epoch 7/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3144 - accuracy: 0.8541 - val_loss: 0.3210 - val_accuracy: 0.8488\n",
      "Epoch 8/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3120 - accuracy: 0.8548 - val_loss: 0.3180 - val_accuracy: 0.8520\n",
      "Epoch 9/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3103 - accuracy: 0.8558 - val_loss: 0.3197 - val_accuracy: 0.8488\n",
      "Epoch 10/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3091 - accuracy: 0.8557 - val_loss: 0.3196 - val_accuracy: 0.8505\n",
      "Epoch 11/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3075 - accuracy: 0.8562 - val_loss: 0.3169 - val_accuracy: 0.8515\n",
      "Epoch 12/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3063 - accuracy: 0.8569 - val_loss: 0.3180 - val_accuracy: 0.8526\n",
      "Epoch 13/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3050 - accuracy: 0.8577 - val_loss: 0.3172 - val_accuracy: 0.8497\n",
      "Epoch 14/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3034 - accuracy: 0.8582 - val_loss: 0.3169 - val_accuracy: 0.8498\n",
      "Epoch 15/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3024 - accuracy: 0.8585 - val_loss: 0.3162 - val_accuracy: 0.8529\n",
      "Epoch 16/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3018 - accuracy: 0.8592 - val_loss: 0.3157 - val_accuracy: 0.8517\n",
      "Epoch 17/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3005 - accuracy: 0.8585 - val_loss: 0.3169 - val_accuracy: 0.8500\n",
      "Epoch 18/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2995 - accuracy: 0.8604 - val_loss: 0.3160 - val_accuracy: 0.8524\n",
      "Epoch 19/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2985 - accuracy: 0.8602 - val_loss: 0.3171 - val_accuracy: 0.8520\n",
      "Epoch 20/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2973 - accuracy: 0.8604 - val_loss: 0.3197 - val_accuracy: 0.8515\n",
      "Epoch 21/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2960 - accuracy: 0.8602 - val_loss: 0.3187 - val_accuracy: 0.8526\n",
      "Epoch 22/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2952 - accuracy: 0.8624 - val_loss: 0.3175 - val_accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2943 - accuracy: 0.8620 - val_loss: 0.3191 - val_accuracy: 0.8535\n",
      "Epoch 24/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2937 - accuracy: 0.8618 - val_loss: 0.3158 - val_accuracy: 0.8505\n",
      "Epoch 25/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2926 - accuracy: 0.8620 - val_loss: 0.3163 - val_accuracy: 0.8518\n",
      "Epoch 26/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2918 - accuracy: 0.8644 - val_loss: 0.3182 - val_accuracy: 0.8489\n",
      "Epoch 27/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2907 - accuracy: 0.8640 - val_loss: 0.3179 - val_accuracy: 0.8509\n",
      "Epoch 28/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2898 - accuracy: 0.8647 - val_loss: 0.3165 - val_accuracy: 0.8485\n",
      "Epoch 29/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2894 - accuracy: 0.8642 - val_loss: 0.3180 - val_accuracy: 0.8521\n",
      "Epoch 30/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2883 - accuracy: 0.8648 - val_loss: 0.3181 - val_accuracy: 0.8486\n",
      "Epoch 31/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2873 - accuracy: 0.8658 - val_loss: 0.3185 - val_accuracy: 0.8526\n",
      "Epoch 32/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2867 - accuracy: 0.8647 - val_loss: 0.3172 - val_accuracy: 0.8478\n",
      "Epoch 33/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2858 - accuracy: 0.8641 - val_loss: 0.3206 - val_accuracy: 0.8492\n",
      "Epoch 34/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2845 - accuracy: 0.8660 - val_loss: 0.3210 - val_accuracy: 0.8465\n",
      "Epoch 35/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2845 - accuracy: 0.8676 - val_loss: 0.3181 - val_accuracy: 0.8500\n",
      "Epoch 36/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2835 - accuracy: 0.8667 - val_loss: 0.3223 - val_accuracy: 0.8480\n",
      "Epoch 37/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2829 - accuracy: 0.8675 - val_loss: 0.3200 - val_accuracy: 0.8480\n",
      "Epoch 38/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2813 - accuracy: 0.8693 - val_loss: 0.3186 - val_accuracy: 0.8521\n",
      "Epoch 39/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2808 - accuracy: 0.8691 - val_loss: 0.3188 - val_accuracy: 0.8478\n",
      "Epoch 40/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2801 - accuracy: 0.8689 - val_loss: 0.3212 - val_accuracy: 0.8469\n",
      "Epoch 41/50\n",
      "814/814 [==============================] - 4s 4ms/step - loss: 0.2793 - accuracy: 0.8703 - val_loss: 0.3227 - val_accuracy: 0.8446\n",
      "Epoch 42/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2785 - accuracy: 0.8691 - val_loss: 0.3233 - val_accuracy: 0.8477\n",
      "Epoch 43/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2782 - accuracy: 0.8700 - val_loss: 0.3278 - val_accuracy: 0.8463\n",
      "Epoch 44/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2772 - accuracy: 0.8699 - val_loss: 0.3236 - val_accuracy: 0.8481\n",
      "Epoch 45/50\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2768 - accuracy: 0.8712 - val_loss: 0.3223 - val_accuracy: 0.8475\n",
      "Epoch 46/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2759 - accuracy: 0.8710 - val_loss: 0.3217 - val_accuracy: 0.8465\n",
      "Epoch 47/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2748 - accuracy: 0.8720 - val_loss: 0.3233 - val_accuracy: 0.8480\n",
      "Epoch 48/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2746 - accuracy: 0.8710 - val_loss: 0.3248 - val_accuracy: 0.8491\n",
      "Epoch 49/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2731 - accuracy: 0.8718 - val_loss: 0.3254 - val_accuracy: 0.8471\n",
      "Epoch 50/50\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2730 - accuracy: 0.8725 - val_loss: 0.3249 - val_accuracy: 0.8460\n",
      "Best epoch: 23\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(features, labels, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4ba6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3860 - accuracy: 0.8227 - val_loss: 0.3392 - val_accuracy: 0.8391\n",
      "Epoch 2/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3348 - accuracy: 0.8439 - val_loss: 0.3265 - val_accuracy: 0.8457\n",
      "Epoch 3/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3259 - accuracy: 0.8490 - val_loss: 0.3242 - val_accuracy: 0.8437\n",
      "Epoch 4/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3218 - accuracy: 0.8492 - val_loss: 0.3227 - val_accuracy: 0.8485\n",
      "Epoch 5/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3181 - accuracy: 0.8527 - val_loss: 0.3227 - val_accuracy: 0.8483\n",
      "Epoch 6/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3161 - accuracy: 0.8523 - val_loss: 0.3214 - val_accuracy: 0.8495\n",
      "Epoch 7/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3140 - accuracy: 0.8542 - val_loss: 0.3198 - val_accuracy: 0.8481\n",
      "Epoch 8/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3121 - accuracy: 0.8541 - val_loss: 0.3231 - val_accuracy: 0.8472\n",
      "Epoch 9/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3105 - accuracy: 0.8548 - val_loss: 0.3171 - val_accuracy: 0.8509\n",
      "Epoch 10/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3087 - accuracy: 0.8552 - val_loss: 0.3169 - val_accuracy: 0.8523\n",
      "Epoch 11/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3070 - accuracy: 0.8561 - val_loss: 0.3167 - val_accuracy: 0.8509\n",
      "Epoch 12/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.3059 - accuracy: 0.8576 - val_loss: 0.3163 - val_accuracy: 0.8524\n",
      "Epoch 13/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3051 - accuracy: 0.8565 - val_loss: 0.3154 - val_accuracy: 0.8511\n",
      "Epoch 14/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3031 - accuracy: 0.8576 - val_loss: 0.3204 - val_accuracy: 0.8521\n",
      "Epoch 15/23\n",
      "814/814 [==============================] - 2s 3ms/step - loss: 0.3023 - accuracy: 0.8579 - val_loss: 0.3161 - val_accuracy: 0.8517\n",
      "Epoch 16/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.3012 - accuracy: 0.8591 - val_loss: 0.3216 - val_accuracy: 0.8485\n",
      "Epoch 17/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2995 - accuracy: 0.8594 - val_loss: 0.3152 - val_accuracy: 0.8526\n",
      "Epoch 18/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2991 - accuracy: 0.8595 - val_loss: 0.3156 - val_accuracy: 0.8517\n",
      "Epoch 19/23\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2977 - accuracy: 0.8597 - val_loss: 0.3168 - val_accuracy: 0.8521\n",
      "Epoch 20/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2966 - accuracy: 0.8601 - val_loss: 0.3161 - val_accuracy: 0.8517\n",
      "Epoch 21/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2961 - accuracy: 0.8621 - val_loss: 0.3145 - val_accuracy: 0.8520\n",
      "Epoch 22/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2953 - accuracy: 0.8619 - val_loss: 0.3152 - val_accuracy: 0.8526\n",
      "Epoch 23/23\n",
      "814/814 [==============================] - 3s 3ms/step - loss: 0.2941 - accuracy: 0.8619 - val_loss: 0.3153 - val_accuracy: 0.8528\n",
      "509/509 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8496\n",
      "[test loss, test accuracy]: [0.31774643063545227, 0.8495792746543884]\n"
     ]
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(features, labels, epochs=best_epoch, validation_split=0.2)\n",
    "eval_result = hypermodel.evaluate(test_features,test_labels)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
